{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolez9911/colab/blob/main/mathofdl/Math_of_DL_L1_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "khfcg5NMZsID"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mathematics of Deep Learning\n",
        "## Lecture 1 Exercises\n",
        "---\n",
        "## 1. Computing the forward pass\n",
        "\n",
        "Consider a neural network with the following architecture.\n",
        "\n",
        "![Alt Text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTz35Zhb7J5zGTwUiIP4zgjQCwztG37ZoEOWg&usqp=CAU)\n",
        "\n",
        "We'll use as a data input the point $x = (1,2,3).$\n",
        "\n",
        "In this exercise, you will practice intializing the weights and baises randomly and computing the forward pass.\n",
        "\n",
        "Assume the hidden layer uses ReLU activation and that the output layer uses a sigmoid activation.\n",
        "\n",
        "A network with 2-dimensional output given by sigmoid functions could be used, for example, to detect the presence of two different objects (ex. a car and/or a tree) in an image. An output of (1,1) means that the model detects both items with 100% certainty, while an output of (0,1) means the model doesn't detect the first item, but does detect the second."
      ],
      "metadata": {
        "id": "0X-Q4EFdAceV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1,2,3])"
      ],
      "metadata": {
        "id": "ozDYkmCdgNsj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Step 1: Randomly initialize the model parameters"
      ],
      "metadata": {
        "id": "xaeVSra4duw0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dGF-M6oDASmA",
        "outputId": "f09cf897-56a1-4a27-8f45-9c3aaa674ba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.8195078 , -0.33701124, -0.89806547, -0.14414848],\n",
              "        [ 2.07070057, -1.60016279, -0.69132874, -0.63841121],\n",
              "        [ 0.56556242, -0.11964872,  0.16038102,  1.26468353]]),\n",
              " array([[ 0.64217211],\n",
              "        [-0.19461406],\n",
              "        [ 0.04393337],\n",
              "        [ 0.37958282]]),\n",
              " array([[ 1.18747811,  0.3550394 ],\n",
              "        [ 0.79659046, -0.4113674 ],\n",
              "        [ 0.7686037 , -0.26712818],\n",
              "        [ 0.67491771,  0.76504376]]),\n",
              " array([[ 0.68039343],\n",
              "        [-0.42912448]]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Use the np.random.randn function to intialize the weights and biases by\n",
        "# sampling each component from a normal distribution.\n",
        "\n",
        "# You should end up with:\n",
        "#   W1 : a 4x3 array of weights for the first layer.\n",
        "#   b1 : a 4D array of biases for the first layer.\n",
        "#   W2: a 2x4 array of weights for the second layer.\n",
        "#   b2 : a 2D array of biases for the second layer.\n",
        "\n",
        "############################\n",
        "# YOUR CODE HERE:\n",
        "W1 = np.random.randn(3, 4)\n",
        "b1 = np.random.randn(4, 1)\n",
        "W2 = np.random.randn(4, 2)\n",
        "b2 = np.random.randn(2, 1)\n",
        "\n",
        "############################\n",
        "W1, b1, W2, b2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Step 2: Define the sigmoid function.\n",
        "Recall the defition of the sigmoid fucntion:\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1+e^{-x}}.\n",
        "$$"
      ],
      "metadata": {
        "id": "cKdFEYSpdpgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that takes an input array x and computes the sigmoid\n",
        "# function on each component.\n",
        "# The expontential function is expressed in numpy as np.exp(x).\n",
        "\n",
        "def sigmoid(x):\n",
        "    '''\n",
        "    x is an n-dimensional numpy array: [x0,x1,...,xn]\n",
        "\n",
        "    returns sigmoidx = [sigmoid(x0),...,sigmoid(xn)]\n",
        "    '''\n",
        "    sigmoidx = 0\n",
        "    ###### YOUR CODE HERE #####\n",
        "    sigmoidx = 1 / (1 + np.exp(x))\n",
        "\n",
        "\n",
        "    ###########################\n",
        "\n",
        "    return sigmoidx"
      ],
      "metadata": {
        "id": "MsaEmDT4cz4n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(x)"
      ],
      "metadata": {
        "id": "6QYZM6krgGqN",
        "outputId": "b77e9f72-000d-4e54-8a55-a5393e68e2fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.26894142, 0.11920292, 0.04742587])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Step 3: Compute the forward pass\n",
        "\n",
        "Recall that the forward pass is computed"
      ],
      "metadata": {
        "id": "-t1MFY4Sg38I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute the forward pass.\n",
        "\n",
        "# Your input is x = np.array([1,2,3]) and your output is a 2d-array.\n",
        "\n",
        "# Hints: In numpy, the product of two matrices A*B is computed via A.dot(B).\n",
        "# For the ReLU function, you can use np.maximum(0,x).\n",
        "\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "#y = np.maximum(0, W2.dot((W1.dot(x) + b1)) + b2)\n",
        "\n",
        "(x.dot(W1) + b1).dot(W2) + b2\n",
        "\n",
        "######################"
      ],
      "metadata": {
        "id": "tCPtsqtOgHqb",
        "outputId": "798ad9a1-a692-4527-e718-7470e722dbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (4,2) (2,1) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4876c7ba01eb>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#y = np.maximum(0, W2.dot((W1.dot(x) + b1)) + b2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,2) (2,1) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BONUS #\n",
        "\n",
        "# Compute the forward pass for the following array corresponding to two input\n",
        "# data samples given below. Your output should be a 2x2 array.\n",
        "\n",
        "X = np.array([[1,2,3],[4,5,6]]).transpose()\n",
        "\n",
        "# We must take the transpose because each data sample should correspond to a\n",
        "# column vector. Numpy handles this automatically for 1D-arrays, but you have\n",
        "# to be careful with 2D-arrays. You must also reshape b1 and b2 into\n",
        "# column vectors.\n",
        "\n",
        "b1 = b1.reshape(4,1)\n",
        "b2 = b2.reshape(2,1)\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################"
      ],
      "metadata": {
        "id": "datFHz4GhWXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Computing the loss"
      ],
      "metadata": {
        "id": "UNw9jaIYlroL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we are training a binary classifier on a single sample. The model output is $\\hat y = 0.7$. i.e. the model predicts a probability of 70% that the sample belongs in the class with the label '1.'\n",
        "\n",
        "Suppose the sample actually belongs to the '0' class, and compute the corresponding log-loss:\n",
        "\n",
        "$$L(y,\\hat y) = -\\frac{1}{n}\\sum_{i=1}^{n}y_i\\log \\hat y_i + (1-y_i)\\log(1-\\hat y_i)$$"
      ],
      "metadata": {
        "id": "A9QCJanWjIML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute the log-loss here:\n"
      ],
      "metadata": {
        "id": "gHGCGW2KiHJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## BONUS ##\n",
        "\n",
        "# Suppose the output layer in the NN from exercise 1 consists\n",
        "# instead of a single node with sigmoid activation.\n",
        "\n",
        "# Randomly initialize the weights and compute the corresponding loss\n",
        "# for an input sample x = [1,1,1] with label y = 0."
      ],
      "metadata": {
        "id": "uPteDXvDmneL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}