{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolez9911/colab/blob/main/mathofdl/Math_of_DL_L1_SOLUTIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "khfcg5NMZsID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mathematics of Deep Learning\n",
        "## Lecture 1 Exercises\n",
        "---\n",
        "## 1. Computing the forward pass\n",
        "\n",
        "Consider a neural network with the following architecture.\n",
        "\n",
        "![Alt Text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTz35Zhb7J5zGTwUiIP4zgjQCwztG37ZoEOWg&usqp=CAU)\n",
        "\n",
        "We'll use as a data input the point $x = (1,2,3).$\n",
        "\n",
        "In this exercise, you will practice intializing the weights and baises randomly and computing the forward pass.\n",
        "\n",
        "Assume the hidden layer uses ReLU activation and that the output layer uses a sigmoid activation.\n",
        "\n",
        "A network with 2-dimensional output given by sigmoid functions could be used, for example, to detect the presence of two different objects (ex. a car and/or a tree) in an image. An output of (1,1) means that the model detects both items with 100% certainty, while an output of (0,1) means the model doesn't detect the first item, but does detect the second."
      ],
      "metadata": {
        "id": "0X-Q4EFdAceV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([1,2,3])"
      ],
      "metadata": {
        "id": "ozDYkmCdgNsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Step 1: Randomly initialize the model parameters"
      ],
      "metadata": {
        "id": "xaeVSra4duw0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGF-M6oDASmA"
      },
      "outputs": [],
      "source": [
        "# Use the np.random.randn function to intialize the weights and biases by\n",
        "# sampling each component from a normal distribution.\n",
        "\n",
        "# You should end up with:\n",
        "#   W1 : a 4x3 array of weights for the first layer.\n",
        "#   b1 : a 4D array of biases for the first layer.\n",
        "#   W2: a 2x4 array of weights for the second layer.\n",
        "#   b2 : a 2D array of biases for the second layer.\n",
        "\n",
        "############################\n",
        "# YOUR CODE HERE:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "```\n",
        "W1 = np.random.randn(4,3)\n",
        "b1 = np.random.randn(4)\n",
        "W2 = np.random.randn(2,4)\n",
        "b2 = np.random.randn(2)\n",
        "```\n",
        "</details>\n",
        "\n"
      ],
      "metadata": {
        "id": "90c8SS7cbJbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Step 2: Define the sigmoid function.\n",
        "Recall the defition of the sigmoid fucntion:\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1+e^{-x}}.\n",
        "$$"
      ],
      "metadata": {
        "id": "cKdFEYSpdpgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that takes an input array x and computes the sigmoid\n",
        "# function on each component.\n",
        "# The expontential function is expressed in numpy as np.exp(x).\n",
        "\n",
        "def sigmoid(x):\n",
        "    '''\n",
        "    x is an n-dimensional numpy array: [x0,x1,...,xn]\n",
        "\n",
        "    returns sigmoidx = [sigmoid(x0),...,sigmoid(xn)]\n",
        "    '''\n",
        "    sigmoidx = 0\n",
        "    ###### YOUR CODE HERE #####\n",
        "\n",
        "\n",
        "\n",
        "    ###########################\n",
        "\n",
        "    return sigmoidx"
      ],
      "metadata": {
        "id": "MsaEmDT4cz4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "\n",
        "```\n",
        "def sigmoid(x):\n",
        "    denom = 1 + np.exp(-x)\n",
        "    sigmoidx = 1/denom\n",
        "\n",
        "    return sigmoidx\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QozL5uc_gmyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(x)"
      ],
      "metadata": {
        "id": "6QYZM6krgGqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Step 3: Compute the forward pass"
      ],
      "metadata": {
        "id": "-t1MFY4Sg38I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute the forward pass.\n",
        "\n",
        "# Your input is x = np.array([1,2,3]) and your output is a 2d-array.\n",
        "\n",
        "# Hints: In numpy, the product of two matrices A*B is computed via A.dot(B).\n",
        "# For the ReLU function, you can use np.maximum(0,x).\n",
        "\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################"
      ],
      "metadata": {
        "id": "tCPtsqtOgHqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "\n",
        "```\n",
        "z1 = W1.dot(x) + b1\n",
        "h1 = np.maximum(0,z1)\n",
        "\n",
        "z2 = W2.dot(h1) + b2\n",
        "y = sigmoid(z2)\n",
        "```\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "ZFPcOK7slNY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BONUS #\n",
        "\n",
        "# Compute the forward pass for the following array corresponding to two input\n",
        "# data samples given below. Your output should be a 2x2 array.\n",
        "\n",
        "X = np.array([[1,2,3],[4,5,6]]).transpose()\n",
        "\n",
        "# We must take the transpose because each data sample should correspond to a\n",
        "# column vector. Numpy handles this automatically for 1D-arrays, but you have\n",
        "# to be careful with 2D-arrays. You must also reshape b1 and b2 into\n",
        "# column vectors.\n",
        "\n",
        "b1 = b1.reshape(4,1)\n",
        "b2 = b2.reshape(2,1)\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "######################"
      ],
      "metadata": {
        "id": "datFHz4GhWXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "\n",
        "\n",
        "```\n",
        "Z1 = W1.dot(X) + b1\n",
        "H1 = np.maximum(0,Z1)\n",
        "\n",
        "Z2 = W2.dot(H1) + b2\n",
        "Y = sigmoid(Z2)\n",
        "```\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "uvHVZ_tIk2nY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2. Computing the loss"
      ],
      "metadata": {
        "id": "UNw9jaIYlroL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we are training a binary classifier on a single sample. The model output is $\\hat y = 0.7$. i.e. the model predicts a probability of 70% that the sample belongs in the class with the label '1.'\n",
        "\n",
        "Suppose the sample actually belongs to the '0' class, and compute the corresponding log-loss:\n",
        "\n",
        "$$L(y,\\hat y) = -\\frac{1}{n}\\sum_{i=1}^{n}y_i\\log \\hat y_i + (1-y_i)\\log(1-\\hat y_i)$$"
      ],
      "metadata": {
        "id": "A9QCJanWjIML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Compute the log-loss here:\n"
      ],
      "metadata": {
        "id": "gHGCGW2KiHJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details><summary>Solution</summary>\n",
        "\n",
        "```\n",
        "loss = -np.log(1-0.7)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "O06hUfsCm9bw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## BONUS ##\n",
        "\n",
        "# Suppose the output layer in the NN from exercise 1 consists\n",
        "# instead of a single node with sigmoid activation.\n",
        "\n",
        "# Randomly initialize the weights and compute the corresponding loss\n",
        "# for an input sample x = [1,1,1] with label y = 0."
      ],
      "metadata": {
        "id": "uPteDXvDmneL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}